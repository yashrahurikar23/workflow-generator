#!/usr/bin/env python3
"""
Test script for AIML API integration with workflow generation
Tests both direct AIML API calls and LlamaIndex integration
"""

import asyncio
import os
import sys
from datetime import datetime

# Add the backend directory to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

def test_aiml_direct_api():
    """Test direct AIML API call using OpenAI SDK"""
    print("üß™ Testing Direct AIML API Integration")
    print("=" * 50)
    
    try:
        from openai import OpenAI

        # Note: Replace with actual AIML API key for real testing
        api_key = "YOUR_AIML_API_KEY"  # Get from https://aimlapi.com/app/keys
        base_url = "https://api.aimlapi.com/v1"
        
        if api_key == "YOUR_AIML_API_KEY":
            print("‚ö†Ô∏è  No AIML API key configured - skipping direct API test")
            print("   To test: Set AIML_API_KEY environment variable or update the script")
            return False
        
        client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        # Test simple completion
        response = client.chat.completions.create(
            model="gpt-4o",  # AIML's latest GPT-4 Omni
            messages=[
                {"role": "system", "content": "You are a workflow automation expert."},
                {"role": "user", "content": "Create a simple workflow to send daily weather emails."}
            ],
            temperature=0.1,
            max_tokens=500
        )
        
        result = response.choices[0].message.content
        print("‚úÖ AIML API Test Successful!")
        print(f"   Model: gpt-4o")
        print(f"   Response: {result[:100]}...")
        return True
        
    except ImportError:
        print("‚ùå OpenAI SDK not available - install with: pip install openai")
        return False
    except Exception as e:
        print(f"‚ùå AIML API Test Failed: {e}")
        return False

async def test_llamaindex_aiml_integration():
    """Test LlamaIndex integration with AIML API"""
    print("\nü§ñ Testing LlamaIndex + AIML Integration")
    print("=" * 50)
    
    try:
        # Import our workflow generator
        # Mock settings for AIML
        import app.core.config as config
        from app.models.workflow import WorkflowGenerateRequest
        from app.services.workflow_generator import WorkflowGenerator

        # Temporarily configure AIML for testing
        original_provider = config.settings.LLM_PROVIDER
        original_key = config.settings.AIML_API_KEY
        
        config.settings.LLM_PROVIDER = "aiml"
        config.settings.AIML_API_KEY = "test_key"  # Would need real key for actual testing
        
        # Create generator
        generator = WorkflowGenerator()
        
        if not generator.use_llm:
            print("‚ö†Ô∏è  LLM not initialized (no API key) - testing template fallback")
        else:
            print("‚úÖ LlamaIndex + AIML integration configured successfully")
        
        # Test workflow generation
        request = WorkflowGenerateRequest(
            prompt="Create a workflow that monitors website uptime and sends alerts when sites go down",
            additional_context="Check every 5 minutes, email admin@company.com on failures"
        )
        
        workflow = await generator.generate_workflow(request)
        
        print(f"‚úÖ Workflow Generated Successfully!")
        print(f"   Name: {workflow.name}")
        print(f"   Description: {workflow.description}")
        print(f"   Steps: {len(workflow.steps)}")
        print(f"   Tags: {', '.join(workflow.tags)}")
        print(f"   Generated by LLM: {workflow.generated_by_llm}")
        print(f"   Provider: {workflow.llm_provider}")
        
        # Restore original settings
        config.settings.LLM_PROVIDER = original_provider
        config.settings.AIML_API_KEY = original_key
        
        return True
        
    except Exception as e:
        print(f"‚ùå LlamaIndex Integration Test Failed: {e}")
        return False

def test_provider_switching():
    """Test switching between different LLM providers"""
    print("\nüîÑ Testing Provider Switching")
    print("=" * 40)
    
    try:
        import app.core.config as config
        from app.services.workflow_generator import WorkflowGenerator
        
        providers_to_test = [
            ("template", None),
            ("openai", "test_openai_key"),
            ("aiml", "test_aiml_key"),
        ]
        
        for provider, api_key in providers_to_test:
            print(f"   Testing provider: {provider}")
            
            # Configure provider
            config.settings.LLM_PROVIDER = provider
            if provider == "openai":
                config.settings.OPENAI_API_KEY = api_key
            elif provider == "aiml":
                config.settings.AIML_API_KEY = api_key
            
            # Create new generator
            generator = WorkflowGenerator()
            
            expected_llm = provider != "template" and api_key is not None
            actual_llm = generator.use_llm
            
            if provider == "template":
                print(f"     ‚úÖ Template provider: LLM={actual_llm} (expected: False)")
            else:
                # With test keys, LLM should be False (invalid keys)
                print(f"     ‚úÖ {provider} provider: LLM={actual_llm} (expected: False with test key)")
        
        print("‚úÖ Provider switching test completed")
        return True
        
    except Exception as e:
        print(f"‚ùå Provider switching test failed: {e}")
        return False

def display_aiml_models():
    """Display available models through AIML API"""
    print("\nüìã AIML API Available Models (Popular)")
    print("=" * 50)
    
    models = {
        "Text/Chat Models": [
            "gpt-4o - Latest GPT-4 Omni (Best overall)",
            "gpt-4o-mini - Faster, cost-effective GPT-4",
            "claude-3-sonnet - Anthropic Claude (Great for structured output)",
            "llama-3-70b - Meta's Llama 3 (Open source)",
            "deepseek-v3 - DeepSeek V3 (Excellent for code)",
            "gemini-1.5-pro - Google Gemini (Multimodal)",
            "grok-2 - xAI's Grok (Latest reasoning model)"
        ],
        "Image Generation": [
            "flux-1.1-pro - Black Forest Labs FLUX",
            "stable-diffusion-3.5 - Stability AI",
            "dall-e-3 - OpenAI DALL-E 3"
        ],
        "Video Generation": [
            "sora-1 - OpenAI Sora",
            "runway-gen3 - Runway ML",
            "luma-dream-machine - Luma Labs"
        ]
    }
    
    for category, model_list in models.items():
        print(f"\n{category}:")
        for model in model_list:
            print(f"  ‚Ä¢ {model}")
    
    print(f"\nüí° Benefits of AIML API:")
    print(f"  ‚Ä¢ 200+ models in one API")
    print(f"  ‚Ä¢ Up to 90% cheaper than direct providers")
    print(f"  ‚Ä¢ OpenAI-compatible (drop-in replacement)")
    print(f"  ‚Ä¢ Latest models available quickly")
    print(f"  ‚Ä¢ Perfect for LlamaIndex integration")

async def main():
    """Run all AIML integration tests"""
    print("üöÄ AIML API Integration Testing Suite")
    print("=" * 60)
    
    # Test 1: Direct AIML API
    direct_success = test_aiml_direct_api()
    
    # Test 2: LlamaIndex Integration
    llama_success = await test_llamaindex_aiml_integration()
    
    # Test 3: Provider Switching
    switch_success = test_provider_switching()
    
    # Display available models
    display_aiml_models()
    
    # Summary
    print("\n" + "=" * 60)
    print("üéØ Test Summary:")
    print(f"   Direct AIML API: {'‚úÖ PASS' if direct_success else '‚ö†Ô∏è  SKIP (no API key)'}")
    print(f"   LlamaIndex Integration: {'‚úÖ PASS' if llama_success else '‚ùå FAIL'}")
    print(f"   Provider Switching: {'‚úÖ PASS' if switch_success else '‚ùå FAIL'}")
    
    print(f"\nüîß Next Steps:")
    print(f"   1. Get AIML API key: https://aimlapi.com/app/keys")
    print(f"   2. Set environment variable: AIML_API_KEY=your_key")
    print(f"   3. Update backend/.env with LLM_PROVIDER=aiml")
    print(f"   4. Restart backend to test with real API calls")

if __name__ == "__main__":
    asyncio.run(main())
